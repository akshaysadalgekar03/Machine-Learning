
# Linear Regression using Mini Batch Gradient from scratch in Python

Linear Regression:
-----------------
In statistics, linear regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables).
Linear regression models are a good starting point for regression tasks. Such models are popular because they can be fit very quickly, and are very interpretable.

Simple Linear Regression;
A straight line fit is a model of the form y = ax + b where a is the slope and b is the intercept.

Gradient Descent:
----------------
Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Gradient descent is an optimization algorithm often used for finding the weights or coefficients of machine learning algorithms.

Types of Gradient Descent Algorithm:

1. Batch gradient descent: 
2. Stochastic gradient descent
3. Mini-batch gradient descent

Mini-batch gradient descent:
Mini-batch gradient descent combines concepts from both batch gradient descent and stochastic gradient descent. It splits the training dataset into small batch sizes and performs updates on each of those batches that are used to calculate and update the model coefficients.

Regularizartion:
---------------
Ridge regression(L2 regularization);
The most common form of regularization is known as ridge regression or L2 which proceeds by penalizing the sum of squares of the model coefficients.

Iris Dataset:
------------
The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems.
The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.
